{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7678689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from glob import glob\n",
    "from numpy import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from time import time\n",
    "import pickle as pkl\n",
    "import os\n",
    "import cv2\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e852d8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ans037/public/cs255-sp22-a00-public/poverty/anon_images/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "_uname = path.split('/')[2]\n",
    "poverty_dir=f'/home/{_uname}/public/cs255-sp22-a00-public/poverty/'\n",
    "image_dir=poverty_dir+'anon_images/'\n",
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e72e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table=f'/home/{_uname}/public/Datasets_public/Final_Project_Data/train.csv'\n",
    "df=pd.read_csv(train_table,index_col=0)\n",
    "df.index=df['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eabdc7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(image):\n",
    "    M = np.load(image)\n",
    "    l = [cv2.resize(M['x'][i, :, :], (20, 20)) for i in range(8)]\n",
    "    return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d8991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(band):\n",
    "    features = {}\n",
    "    features['mean'] = np.mean(band)\n",
    "    features['std'] = np.std(band)\n",
    "    features['skewness'] = skew(band)\n",
    "    features['kurtosis'] = kurtosis(band)\n",
    "    features['percentile_25'] = np.percentile(band, 25)\n",
    "    features['percentile_50'] = np.percentile(band, 50)\n",
    "    features['percentile_75'] = np.percentile(band, 75)\n",
    "    return features\n",
    "\n",
    "def process_outliers(x):\n",
    "    _min = np.percentile(x, 0.1)\n",
    "    _max = np.percentile(x,99.9)\n",
    "        \n",
    "    x = (x - _min)/(_max - _min)\n",
    "    x = np.where(x > 1, 1, x)\n",
    "    x = np.where(x < 0, 0, x)\n",
    "    return x\n",
    "    \n",
    "\n",
    "def calculate_indices(df, train=True):\n",
    "    if train:\n",
    "        df = df.drop(['filename', 'wealthpooled'], axis=1)\n",
    "    else:\n",
    "        df = df.drop(['filename'], axis=1)\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    band_names = ['Red', 'Green', 'Blue', 'NIR', 'SWIR1', 'SWIR2', 'TEMP1', 'NL']\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    for i in range(len(band_names)):\n",
    "        df_copy[band_names[i]] = df_copy.apply(lambda x: x['Image'][i, :, :], axis=1)\n",
    "\n",
    "    # Calculate the bare soil indices\n",
    "    df_copy['MBI'] = (df_copy['SWIR1'] - df_copy['SWIR1'] - df_copy['NIR']) / (df_copy['SWIR1'] + df_copy['SWIR2'] + df_copy['NIR']) + 0.5\n",
    "    df_copy['BSI'] = (df_copy['SWIR1'] + df_copy['Red'] - df_copy['NIR'] - df_copy['Blue']) / (df_copy['SWIR1'] + df_copy['Red'] + df_copy['NIR'] + df_copy['Blue'])\n",
    "    df_copy['NDSI1'] = (df_copy['SWIR1'] - df_copy['NIR']) / (df_copy['SWIR1'] + df_copy['NIR'])\n",
    "    df_copy['NDSI2'] = (df_copy['SWIR1'] - df_copy['Green']) / (df_copy['SWIR1'] + df_copy['Green'])\n",
    "    df_copy['BI'] = df_copy['Red'] + df_copy['SWIR1'] - df_copy['NIR']\n",
    "    df_copy['DBSI'] = (df_copy['SWIR1'] - df_copy['Green']) / (df_copy['SWIR1'] + df_copy['Green']) - (df_copy['NIR'] - df_copy['Red']) / (df_copy['NIR'] + df_copy['Red'])\n",
    "\n",
    "    df_copy['BAEI'] = (df_copy['Red'] + 0.3) / (df_copy['Green'] + df_copy['SWIR1'])\n",
    "    df_copy['BUI'] = (df_copy['SWIR1'] - df_copy['NIR']) / (df_copy['SWIR1'] + df_copy['NIR']) - (df_copy['NIR'] - df_copy['Red']) / (df_copy['NIR'] + df_copy['Red'])\n",
    "    df_copy['NBI'] = (df_copy['Red'] - df_copy['SWIR1']) / df_copy['NIR']\n",
    "    df_copy['BRBA'] = df_copy['Red'] / df_copy['SWIR1']\n",
    "    df_copy['IBI'] = (2 * df_copy['SWIR1'] / (df_copy['SWIR1'] + df_copy['NIR'])) - ((df_copy['NIR'] / (df_copy['NIR'] - df_copy['Red']) + df_copy['Green'] / (df_copy['Green'] + df_copy['SWIR1'])) / 2) * (df_copy['SWIR1'] / (df_copy['SWIR1'] + df_copy['NIR'])) + (df_copy['NIR'] / (df_copy['NIR'] - df_copy['Red']) + df_copy['Green'] / (df_copy['Green'] + df_copy['SWIR1']))\n",
    "    df_copy['NDCCI'] = (df_copy['NIR'] - df_copy['Green']) / (df_copy['NIR'] + df_copy['Green'])\n",
    "\n",
    "    # Vegetation indices\n",
    "    df_copy['NDVI'] = (df_copy['NIR'] - df_copy['Red']) / (df_copy['NIR'] + df_copy['Red'])\n",
    "    df_copy['SAVI'] = (df_copy['NIR'] - df_copy['Red']) / (df_copy['NIR'] + df_copy['Red'] + 0.5) * (1 + 0.5)\n",
    "    df_copy['NDMI'] = (df_copy['NIR'] - df_copy['SWIR1']) / (df_copy['NIR'] + df_copy['SWIR1'])\n",
    "\n",
    "    # Built-up area indices\n",
    "    df_copy['DBI'] = (df_copy['Blue'] - df_copy['TEMP1']) / (df_copy['Blue'] + df_copy['TEMP1']) - (df_copy['NIR'] - df_copy['Red']) / (df_copy['NIR'] + df_copy['Red'])\n",
    "    df_copy['NBAI'] = ((df_copy['SWIR2'] - df_copy['SWIR1']) / df_copy['Green']) / ((df_copy['SWIR2'] + df_copy['SWIR1']) / df_copy['Green'])\n",
    "    df_copy['NDBI'] = (df_copy['SWIR1'] - df_copy['NIR']) / (df_copy['SWIR1'] + df_copy['NIR'])\n",
    "\n",
    "    indices = ['MBI', 'BSI', 'NDSI1', 'NDSI2', 'BI', 'DBSI', 'BAEI', 'BUI', 'NBI', 'BRBA', 'IBI', 'NDCCI', 'NDVI', 'SAVI', 'NDMI', 'DBI', 'NBAI', 'NDBI']\n",
    "\n",
    "    for feature in list(indices + band_names):\n",
    "        df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
    "        df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
    "        # df[f'{feature}_skewness'] = df[f'{feature}'].apply(lambda x: extract_features(x)['skewness'])\n",
    "        # df[f'{feature}_kurtosis'] = df[f'{feature}'].apply(lambda x: extract_features(x)['kurtosis'])\n",
    "        df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
    "        df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
    "        df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
    "\n",
    "    # df = df.drop(band_names + indices, axis=1)\n",
    "    df = df.drop('Image', axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9eb65e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = 'data/model.pkl'\n",
    "D = pkl.load(open(pickle_file,'rb'))\n",
    "\n",
    "for k in D:\n",
    "    globals()[k] = D[k]\n",
    "scaling_mean = mean\n",
    "scaling_std = std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "751a28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_list = [x['bst'] for x in styled_logs[0]['log']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ae4f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Iterate over test sets\n",
    "folds=[{'in':'country_test_reduct.csv','out':'results_country.csv'},\n",
    "      {'in':'random_test_reduct.csv','out':'results.csv'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbbecb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_326/4189309390.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_326/4189309390.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_326/4189309390.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_326/4189309390.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_326/4189309390.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_326/4189309390.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "data/results_country.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_326/4189309390.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_326/4189309390.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_326/4189309390.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_326/4189309390.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_326/4189309390.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_326/4189309390.py:64: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_326/4189309390.py:65: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_326/4189309390.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_326/4189309390.py:69: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_326/4189309390.py:70: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df_copy[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "data/results.csv\n"
     ]
    }
   ],
   "source": [
    "for fold_i in range(len(folds)):\n",
    "    fold=folds[fold_i]\n",
    "\n",
    "    #load table entries\n",
    "    test_csv = f'/home/{_uname}/public/Datasets_public/Final_Project_Data/{fold[\"in\"]}'\n",
    "    test = pd.read_csv(test_csv,index_col=0)\n",
    "    test.index = test['filename']\n",
    "    test.shape\n",
    "    \n",
    "    out = pd.DataFrame()\n",
    "    out['filename'] = test['filename']\n",
    "    out['urban'] = test['urban']\n",
    "    out.set_index('filename', inplace=True)\n",
    "    \n",
    "    test['Image'] = test.apply(lambda x: getImage(image_dir + '/'+ x['filename']), axis=1)\n",
    "    \n",
    "    test = calculate_indices(test, train=False)\n",
    "    \n",
    "    X_test = test\n",
    "    y_test = np.zeros(test.shape[0])\n",
    "    \n",
    "    dtest = xgb.DMatrix(X_test, label=y_test, enable_categorical=True)\n",
    "    \n",
    "    Preds = np.zeros([X_test.shape[0],len(bst_list)])\n",
    "    \n",
    "    for i in range(len(bst_list)):\n",
    "        # Preds[:,i]=bst_list[i].predict(dtest,output_margin=True)\n",
    "        bst = bst_list[i]\n",
    "        y_pred = bst.predict(dtest,output_margin=True, ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "        #y_pred = np.round(y_pred/(np.max(y_pred) - np.min(y_pred)),2)\n",
    "        Preds[:,i] = y_pred\n",
    "        \n",
    "    #Preds=(Preds-scaling_mean)/scaling_std # apply overall score scaling\n",
    "    \n",
    "    _mean=np.mean(Preds,axis=1)\n",
    "    _std=np.std(Preds,axis=1)\n",
    "    \n",
    "    pred_wo_abstention = (2 * (_mean > 0)) - 1\n",
    "\n",
    "    # Apply threshold-based approach\n",
    "    threshold = 0.5  # Adjust the threshold value as per your requirement\n",
    "    uncertain_indices = np.abs(_mean) < threshold * np.abs(_std)\n",
    "    pred_with_abstention = pred_wo_abstention.copy()\n",
    "    pred_with_abstention[uncertain_indices] = 0\n",
    "    \n",
    "    if fold_i == 0:\n",
    "        out['pred_with_abstention'] = pred_with_abstention\n",
    "    else:\n",
    "        out['pred_wo_abstention'] = pred_wo_abstention\n",
    "    \n",
    "    \n",
    "    outFile=f'data/{fold[\"out\"]}'\n",
    "    out.to_csv(outFile)\n",
    "    print('\\n\\n'+'-'*60)\n",
    "    print(outFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31164032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
