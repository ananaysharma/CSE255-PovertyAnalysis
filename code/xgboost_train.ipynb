{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7678689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/IPython/core/magics/pylab.py:159: UserWarning: pylab import has clobbered these variables: ['time', 'copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from glob import glob\n",
    "from numpy import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "from time import time\n",
    "import pickle as pkl\n",
    "import os\n",
    "import cv2\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e852d8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ans037/public/cs255-sp22-a00-public/poverty/anon_images/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "_uname = path.split('/')[2]\n",
    "poverty_dir=f'/home/{_uname}/public/cs255-sp22-a00-public/poverty/'\n",
    "image_dir=poverty_dir+'anon_images/'\n",
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e72e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_table=f'/home/{_uname}/public/Datasets_public/Final_Project_Data/train.csv'\n",
    "df=pd.read_csv(train_table,index_col=0)\n",
    "df.index=df['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eabdc7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImage(image):\n",
    "    M = np.load(image)\n",
    "    l = [cv2.resize(M['x'][i, :, :], (20, 20)) for i in range(8)]\n",
    "    return np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46c6049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_pickle('df1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8000ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'urban', 'label', 'nl_mean', 'MBI_mean', 'MBI_std',\n",
       "       'MBI_skewness', 'MBI_kurtosis', 'MBI_percentile_25',\n",
       "       'MBI_percentile_50',\n",
       "       ...\n",
       "       'TEMP1_percentile_25', 'TEMP1_percentile_50', 'TEMP1_percentile_75',\n",
       "       'NL_mean', 'NL_std', 'NL_skewness', 'NL_kurtosis', 'NL_percentile_25',\n",
       "       'NL_percentile_50', 'NL_percentile_75'],\n",
       "      dtype='object', length=186)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2fe56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Image'] = df.apply(lambda x: getImage(image_dir + '/'+ x['filename']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e45575ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44d8991e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(band):\n",
    "    features = {}\n",
    "    features['mean'] = np.mean(band)\n",
    "    features['std'] = np.std(band)\n",
    "    features['skewness'] = skew(band)\n",
    "    features['kurtosis'] = kurtosis(band)\n",
    "    features['percentile_25'] = np.percentile(band, 25)\n",
    "    features['percentile_50'] = np.percentile(band, 50)\n",
    "    features['percentile_75'] = np.percentile(band, 75)\n",
    "    return features\n",
    "\n",
    "def process_outliers(x):\n",
    "    _min = np.percentile(x, 0.1)\n",
    "    _max = np.percentile(x,99.9)\n",
    "        \n",
    "    x = (x - _min)/(_max - _min)\n",
    "    x = np.where(x > 1, 1, x)\n",
    "    x = np.where(x < 0, 0, x)\n",
    "    return x\n",
    "    \n",
    "\n",
    "def calculate_indices(df, train=True):\n",
    "    if train:\n",
    "        df = df.drop(['filename', 'wealthpooled'], axis=1)\n",
    "    else:\n",
    "        df = df.drop(['filename'], axis=1)\n",
    "    \n",
    "    df = df.reset_index(drop=True)\n",
    "    band_names = ['Red', 'Green', 'Blue', 'NIR', 'SWIR1', 'SWIR2', 'TEMP1', 'NL']\n",
    "    \n",
    "    for i in range(len(band_names)):\n",
    "        df[band_names[i]] = df.apply(lambda x: x['Image'][i, :, :], axis=1)\n",
    "\n",
    "    # Calculate the bare soil indices\n",
    "    df['MBI'] = (df['SWIR1'] - df['SWIR1'] - df['NIR']) / (df['SWIR1'] + df['SWIR2'] + df['NIR']) + 0.5\n",
    "    df['BSI'] = (df['SWIR1'] + df['Red'] - df['NIR'] - df['Blue']) / (df['SWIR1'] + df['Red'] + df['NIR'] + df['Blue'])\n",
    "    df['NDSI1'] = (df['SWIR1'] - df['NIR']) / (df['SWIR1'] + df['NIR'])\n",
    "    df['NDSI2'] = (df['SWIR1'] - df['Green']) / (df['SWIR1'] + df['Green'])\n",
    "    df['BI'] = df['Red'] + df['SWIR1'] - df['NIR']\n",
    "    df['DBSI'] = (df['SWIR1'] - df['Green']) / (df['SWIR1'] + df['Green']) - (df['NIR'] - df['Red']) / (df['NIR'] + df['Red'])\n",
    "\n",
    "    df['BAEI'] = (df['Red'] + 0.3) / (df['Green'] + df['SWIR1'])\n",
    "    df['BUI'] = (df['SWIR1'] - df['NIR']) / (df['SWIR1'] + df['NIR']) - (df['NIR'] - df['Red']) / (df['NIR'] + df['Red'])\n",
    "    df['NBI'] = (df['Red'] - df['SWIR1']) / df['NIR']\n",
    "    df['BRBA'] = df['Red'] / df['SWIR1']\n",
    "    df['IBI'] = (2 * df['SWIR1'] / (df['SWIR1'] + df['NIR'])) - ((df['NIR'] / (df['NIR'] - df['Red']) + df['Green'] / (df['Green'] + df['SWIR1'])) / 2) * (df['SWIR1'] / (df['SWIR1'] + df['NIR'])) + (df['NIR'] / (df['NIR'] - df['Red']) + df['Green'] / (df['Green'] + df['SWIR1']))\n",
    "    df['NDCCI'] = (df['NIR'] - df['Green']) / (df['NIR'] + df['Green'])\n",
    "\n",
    "    # Vegetation indices\n",
    "    df['NDVI'] = (df['NIR'] - df['Red']) / (df['NIR'] + df['Red'])\n",
    "    df['SAVI'] = (df['NIR'] - df['Red']) / (df['NIR'] + df['Red'] + 0.5) * (1 + 0.5)\n",
    "    df['NDMI'] = (df['NIR'] - df['SWIR1']) / (df['NIR'] + df['SWIR1'])\n",
    "\n",
    "    # Built-up area indices\n",
    "    df['DBI'] = (df['Blue'] - df['TEMP1']) / (df['Blue'] + df['TEMP1']) - (df['NIR'] - df['Red']) / (df['NIR'] + df['Red'])\n",
    "    df['NBAI'] = ((df['SWIR2'] - df['SWIR1']) / df['Green']) / ((df['SWIR2'] + df['SWIR1']) / df['Green'])\n",
    "    df['NDBI'] = (df['SWIR1'] - df['NIR']) / (df['SWIR1'] + df['NIR'])\n",
    "\n",
    "    indices = ['MBI', 'BSI', 'NDSI1', 'NDSI2', 'BI', 'DBSI', 'BAEI', 'BUI', 'NBI', 'BRBA', 'IBI', 'NDCCI', 'NDVI', 'SAVI', 'NDMI', 'DBI', 'NBAI', 'NDBI']\n",
    "\n",
    "    for feature in list(indices + band_names):\n",
    "        df[f'{feature}_mean'] = df[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
    "        df[f'{feature}_std'] = df[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
    "        # df[f'{feature}_skewness'] = df[f'{feature}'].apply(lambda x: extract_features(x)['skewness'])\n",
    "        # df[f'{feature}_kurtosis'] = df[f'{feature}'].apply(lambda x: extract_features(x)['kurtosis'])\n",
    "        df[f'{feature}_percentile_25'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
    "        df[f'{feature}_percentile_50'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
    "        df[f'{feature}_percentile_75'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
    "\n",
    "    df = df.drop(band_names + indices, axis=1)\n",
    "    df = df.drop('Image', axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "725fb5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_107/2623392933.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_107/2623392933.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_107/2623392933.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_107/2623392933.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_107/2623392933.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_107/2623392933.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_107/2623392933.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_107/2623392933.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_107/2623392933.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_107/2623392933.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_107/2623392933.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_107/2623392933.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_107/2623392933.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_107/2623392933.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_107/2623392933.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_107/2623392933.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_107/2623392933.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_107/2623392933.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_107/2623392933.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_107/2623392933.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_107/2623392933.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_107/2623392933.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_107/2623392933.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_107/2623392933.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_107/2623392933.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_107/2623392933.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_107/2623392933.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_107/2623392933.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_107/2623392933.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_107/2623392933.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_107/2623392933.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_107/2623392933.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_107/2623392933.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_107/2623392933.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_107/2623392933.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_107/2623392933.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_107/2623392933.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_107/2623392933.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_107/2623392933.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_107/2623392933.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_107/2623392933.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_107/2623392933.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_107/2623392933.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_107/2623392933.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_107/2623392933.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_107/2623392933.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_107/2623392933.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_107/2623392933.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n",
      "/tmp/ipykernel_107/2623392933.py:62: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_mean'] = df[f'{feature}'].apply(lambda x: extract_features(x)['mean'])\n",
      "/tmp/ipykernel_107/2623392933.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_std'] = df[f'{feature}'].apply(lambda x: extract_features(x)['std'])\n",
      "/tmp/ipykernel_107/2623392933.py:66: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_25'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_25'])\n",
      "/tmp/ipykernel_107/2623392933.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_50'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_50'])\n",
      "/tmp/ipykernel_107/2623392933.py:68: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'{feature}_percentile_75'] = df[f'{feature}'].apply(lambda x: extract_features(x)['percentile_75'])\n"
     ]
    }
   ],
   "source": [
    "df1 = calculate_indices(df1, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c612da4",
   "metadata": {},
   "source": [
    "## Training XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49c72a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_plst():\n",
    "    param = {}\n",
    "    param['max_depth']= 7  # depth of tree\n",
    "    param['learning_rate'] = 0.1     \n",
    "    param['objective'] = 'binary:logistic'\n",
    "    param['nthread'] = 7 # Number of threads used\n",
    "    param['eval_metric'] = 'logloss'\n",
    "    return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a311d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(_mean, _std):\n",
    "#     # YOUR CODE HERE\n",
    "#     #raise NotImplementedError()\n",
    "    \n",
    "#     pred_wo_abstention=(2*(_mean>0))-1\n",
    "#     pred_with_abstention=copy(pred_wo_abstention)\n",
    "#     pred_with_abstention[_std>abs(_mean)]=0\n",
    "            \n",
    "#     return pred_wo_abstention, pred_with_abstention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95b1a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_scores(styled_logs,title=None,normalize=True, check=False):\n",
    "\n",
    "    for st_log in styled_logs:\n",
    "        log = st_log['log']\n",
    "        \n",
    "        #find normalization constants\n",
    "        if normalize:\n",
    "            all_pred=[]\n",
    "            for i in range(len(log)):\n",
    "                X = log[i]\n",
    "                y_pred = X['y_pred']\n",
    "                all_pred.append(y_pred)\n",
    "            all_pred = np.concatenate(all_pred)\n",
    "            _mean = np.mean(all_pred)\n",
    "            _std = np.std(all_pred)\n",
    "        else:\n",
    "            _mean=0\n",
    "            _std=1\n",
    "\n",
    "    if title:\n",
    "        return _mean,_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a5611df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_train):\n",
    "    \n",
    "    X = df_train.drop('label', axis=1)\n",
    "    y = df_train['label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    log = bootstrap_pred(X_train, X_test, y_train, y_test, n_bootstrap=100, \\\n",
    "                                           bootstrap_size=len(X_train))\n",
    "    \n",
    "    styled_logs=[\n",
    "        {   'log':log\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return styled_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97f828fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_pred(X_train, X_test, y_train, y_test, n_bootstrap, bootstrap_size, \\\n",
    "                   num_round=200, plst=xgboost_plst()):\n",
    "    \n",
    "    pred_matrix = np.empty((n_bootstrap, len(X_test)))\n",
    "    \n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "    log = []\n",
    "\n",
    "    for i in range(n_bootstrap):\n",
    "\n",
    "        boot_idx = np.random.choice(X_train.index, size=bootstrap_size, replace=True)\n",
    "        X_sample, y_sample = X_train.loc[boot_idx], y_train.loc[boot_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_sample, label=y_sample)\n",
    "\n",
    "        evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "\n",
    "        plst=xgboost_plst()\n",
    "\n",
    "        bst = xgb.train(plst, dtrain, num_boost_round=num_round, evals=evallist, verbose_eval=False)\n",
    "\n",
    "        y_pred = bst.predict(dtest,output_margin=True, ntree_limit=bst.best_ntree_limit)\n",
    "\n",
    "        y_pred = np.round(y_pred/(np.max(y_pred) - np.min(y_pred)),2)\n",
    "        \n",
    "        margin_scores = y_pred\n",
    "        sorted_scores = np.sort(margin_scores)\n",
    "        filtered_scores = sorted_scores[int(0.1 * len(sorted_scores)):int(0.9 * len(sorted_scores))+1]\n",
    "\n",
    "        log.append({\n",
    "            'i':i,\n",
    "            'bst':bst,\n",
    "            'y_pred': filtered_scores\n",
    "        })\n",
    "\n",
    "    return log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e72a7e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n",
      "/home/ans037/.local/lib/python3.9/site-packages/xgboost/core.py:122: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picklefile= data/model.pkl\n"
     ]
    }
   ],
   "source": [
    "styled_logs = train(df1)\n",
    "\n",
    "_mean,_std = calc_scores(styled_logs,title='All')\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "pickle_file='data/model.pkl'\n",
    "\n",
    "Dump={'styled_logs':styled_logs,\n",
    "      'mean':_mean,\n",
    "      'std':_std}\n",
    "pkl.dump(Dump,open(pickle_file,'wb'))\n",
    "print('picklefile=',pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31164032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
